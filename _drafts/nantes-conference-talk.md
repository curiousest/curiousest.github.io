# title

Writing with hallucinations

# abstract


This talk explores a writing system that feeds on LLM hallucinations.

I’ll share how I fine-tuned and orchestrated LLMs, not to control their output, but to provoke unexpected forms of meaning. By shaping the training data and then building filters, I created a system that generates millions of tokens in search of phrases that surprise their creator.

I use this method to write science fiction and the result is a way of working with language that can also be used for stylistic prototyping, exploratory research tools, and building new kinds of language-driven systems. It’s a method for producing original patterns of thought from noise and turning hallucinations into something worth consuming.

By the end of the talk, you’ll have a blueprint for working _with_ the grain of LLM behaviour, rather than against it. Freeing the sublime in generative AI rather than controlling it.

---

## references



---

I built a system to help me write science fiction short stories. It's not a co-pilot, not an agent. I have a particular writing style that complements prompting and text-generation, so I developed a process using LLMs to automate parts of that very particular writing style.

The writing system and process takes advantage of hallucinations. For one story, I fine-tuned five models and generated over 5m tokens, searching for satisfying phrases that no human would write.

You can apply the learnings from my experience to any data-authoring application.

We should be producing new genres of art.
AI should help us create art that wasn't possible to make before.

## references




# slides

1. Play 3 songs (classic, modern, LLM)
2. Writing samples, how to integrate manually, show integrated afterwards (highlight AI vs mine vs glue)
3. Overall architecture
4. Example prompts
5. Stats



Outlier machines.
Someone dear to me once said, "People write mediocre stuff all the time, even in great works. What matters is the few passages or ideas that are really exceptional."