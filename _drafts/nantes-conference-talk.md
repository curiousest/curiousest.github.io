# title

Creative writing with hallucinations

# abstract


With a few dollars of compute, LLMs can produce more text than a human ever could. Almost all of it is noise. This is a system for finding diamonds buried in the avalanche.

I’ll share how I fine-tuned and orchestrated LLMs to provoke unexpected forms of meaning. By shaping the training data and then building filters, I created a system that generates millions of tokens in search of phrases that surprise their creator. I use this method to write science fiction, but it can also be used for stylistic prototyping, exploratory research tools, and building new kinds of language-driven systems.

By the end of the talk, you’ll have a blueprint for working _with_ the grain of LLM behaviour, rather than against it. Freeing the sublime that is distilled in generative AI rather than constraining it.

---

## references

example output short story:
https://curiousest.com/adam-alone-in-the-evening/

---

I built a system to help me write science fiction short stories. It's not a co-pilot, not an agent. I have a particular writing style that complements prompting and text-generation, so I developed a process using LLMs to automate parts of that very particular writing style.

The writing system and process takes advantage of hallucinations. For one story, I fine-tuned five models and generated over 5m tokens, searching for satisfying phrases that no human would write.

You can apply the learnings from my experience to any data-authoring application.

We should be producing new genres of art.
AI should help us create art that wasn't possible to make before.

## references




# slides

1. Play 3 songs (classic, modern, LLM)
2. Writing samples, how to integrate manually, show integrated afterwards (highlight AI vs mine vs glue)
3. Overall architecture
4. Example prompts
5. Stats



Outlier machines.
Someone dear to me once said, "People write mediocre stuff all the time, even in great works. What matters is the few passages or ideas that are really exceptional."