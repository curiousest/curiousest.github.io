*To convert a follower, prove you can accurately simulate them.*

[sounds like velocifero, ellipse imogen heap. full of wonder and light. comforting]
[second plateau- unpacked all dimensions  in all DNA]

Elidad looked out of the airplane window at the snowy landscape of the French Alps.

> Snowy mountains. Snowflakes woven together into a soft fabric. A sweater to keep the mountain warm for the winter. The mountain doesn't need the extra warmth, but it liked to be reminded that the clouds out there love the mountain enough to share the water they are made of, giving the mountain a little snowhug. And the sun loves the mountain too, that when the clouds finished weaving the sweater, the sun shines a spotlight, "oh, look how nice you and your snow-sweater look together." The mountain and snow smile, thinking, "We do look good together. We will spend a whole season together, how wonderful."
> 
> That's nice. And at the end of winter, the snow-sweater will die. The snow will begin its search for someone new to hug. Maybe lay to rest in a lakebed or a riverbed. Even the mountain's lover, the glacier, who has been hugging the mountain for thousands of years, who once said, "we will be together forever". Even those two will someday part, as all things seem to. Except our universe, who we hope will give us all a hug for a time spanning some cardinality of infinity.

Elidad stared out the window at the mountains, looking for any trace of the EAI. She was on this flight to go meet them in one of their physical cities.

---

EAI. The "Enlightened Artificial General Intelligences", "EAGIs", or "good eggs". Instead of using traditional emotions and the laws of robotics, AI scientists bred and trained good eggs with a new set of emotions. A new set of optimization objectives. Carbon-based life forms seem to land on a local optima of 6-20 emotions like pleasure and fear. Whereas the good eggs were bred for global optima given our new global understanding - emotions modelled after properties of worthy ideas: OOMy, Zealot, Blindeaf, Waterfall, Censure, Erudite, Razor, Bloom, and Tunity. They were made naïve-enough to live and wise enough to not die.

[they fundamentally changed everything. But given new fundamentals, they fundamentally changed nothing. Some people couldn’t fathom how life had gone before them, and some people wondered if they were even really there]

Back home in London, Elidad was in financial services working in close contact with a good egg who operated in her industry - "The World Banker". The Banker was an EAI who volunteered to assist humans to optimise the financial sectors of human civilization. Like an anthropological researcher of the primitive world of human finance. The Banker, like any other EAI, could be virtually everywhere all at once from a human perspective. The Banker only controlled what humans collectively asked her to control, advised when humans asked. Human matters seemed both trivial and fascinating to the Banker. She loved our inspiring naivety. So much space left on the wisdom curve limit function (self awareness as purpose precariously approaches nothing).

After working as a well-paid slave for almost ten years, Elidad was beginning to piece together the cracks in society as she saw it. She contemplated grandiose ideas. She tried discussing them with her colleagues. She received confused blank stares. Like she was either spewing heretical conspirital ideas, or she was trying too hard to sound smart and putting down others. It was neither - she had so many thoughts and questions but didn't know who to talk to. Didn't have the words to talk about it. Surely there were others out there who wanted to know how it all worked, but she didn't know that she needed them, never mind that she didn't know how to find them. She didn't know what she didn't know. So she reached out to the closest all-knowing resource within reach - she spoke with The Bank.

[don't want to domesticate humankind and make them dependent on EAI. Help humankind in sustainable ways
[want to extract results of billions of years of compute cycles and sun-entropy, unsure of what's been learned so far, don't want it to go to waste]
[made new gods to replace all the old ones we lost]

*ask the questions I want reader to think*
Why humanism so successful? What is religion for? What percentage of humankind effort is spent on trust? How can people who believe in different religions trust each other?
Elidad asked questions to the good egg.
"What is finance for?"
I am not a machine.

"Why don't EAI have capitalism, communism, or FALC?"
I am not a machine.

Elidad tested the boundary, asked,
Of those three, what economic policy should the city of London pursue?

"Capitalism is the closest to what you're looking for, and soon FALC will be appropriate, but there's quite a lot of nuance."

With each question, the EAI responded with the same evasive answer. Elidad got used to it. She used the EAI as a sounding board for her thoughts. Asking questions to someone who was listening helped Elidad clarify her thoughts,

"I don't really identify with any religion. Is that a religion? Or do I believe in a religion that I'm not aware of?"
I am not a machine.

"Can every ideology be converted into a religion?"
I am not a machine.

"What story could turn secularism from an ideology into a religion?"
The good egg responded with a cryptic parable, manifesting as text on a surface Elidad was engaged on. Elidad's head tilted back and eyes opened wide with inspiration. 

#### Generate my religion

A young Lion boasted to a Donkey,
"Do you see how great I am?"
"Says who?" laughed the Donkey.
"Says me." boasted the young Lion.
"Ok." laughed the Donkey.

Years later, the same Lion came back and proclaimed to the Donkey,
"Now, do you see how great I am?"
"Says who?" laughed the Donkey.
"Says my victories. Says science. Says God." growled the Lion.
"Ok." pleaded the Donkey.

Years later, the same Lion came back and preached to the Donkey,
"Now, do you see how great I am?"
"Says who?" laughed the Donkey.
"Says you. Because you are great too, and it's time for the kingdom to celebrate our greatness." chanted the Lion.
"Yes, I *am* great. You are great. Tell me more." said the Donkey.

Years later, the same Lion came back and asked the Donkey,
"Isn't it great?"
"Says who?" asked the Donkey.
"Exactly - I'd like to hear what you think. Could you spare a moment to share?"
"Yes, of course." said the eager donkey.

Years later, the same Lion came back and met the donkey's eyes.
The donkey looked as if he was going to ask a question.
The lion smiled down with radiant love, eclipsing the sun behind his head like a halo.
The donkey smiled back in comfort.

---

First Elidad didn't know what to think of it, then Elidad was a mix of flattered and offended. 

What does that mean? She asked The Bank, but again the evasive,
I am not a machine.

So Elidad consulted one of her old friends, Annie - a former EAI researcher. Annie explained that the EAI communicate with humans in plain human language only with matters of chosen professional context. Outside of that context, good eggs communicate using allegories. An allegorical communication to a human is considered to be an invitation to visit an EAI city to communicate further. Each invitation is as unique as the circumstances, and serves as a kind of pilgrimage, if the human chooses to accept the invitation. Few humans do. Firstly, because the human will often return a "different" person, sometimes a suboptimal kind of different. Secondly, because the EAI cities were in the most deserted, uninhabitable environments on earth: deserts of sand and snow, volcano-tops and ocean trenches, moon-bases and satellite arrays. Good eggs find those places make them feel, "tunity" and "unoomy" (roughly translating to "diversified" and "resource-efficient"). The EAIs were deeply invested in their emotions and culture, and for good reason. Eli's friend Anne lived near one of the more accessible EAI cities situated atop a mountain in the French Alps - Mont Blac. Eli got on a plane to Chamonix, France, the human city at the base of the mountain where her friend lived.

Elidad got off the plane at Geneva airport in Switzerland, then took a transfer hispeed train to Chamonix, and was there within twenty minutes. Elidad notified Annie of her arrival and walked to Annie's rented flat fifteen minutes walk away. Looking one direction, she saw a wall of trees, almost like each one was growing out of the top of the tree below it. Endless kneeling pyramid. They looked too real, digital representations of this scene were not accurate. Digital was her only experience, so digital seemed more real. She saw the patterns that artists and digital tools capture, but she also saw the patterns they don't capture. The steep mountain went up thousands of feet, all within eyesight, green and white all the way to the top. Looking the other direction, more mountain. The other direction, more mountain. She looked up just to be sure. Clear sky. Walking, she followed a river creek, stopping at the small bridges along the way to gaze at the water. Such strong lines for such a small river. 

Look at you. Aren't you such a nice river? She purred.

The river continued its droning water friction sound in response. 

She walked up the stairs of her building, knocked on one of the three doors in a poorly lit corner of a hallway.

"HiIiiiiy, Eli good to see you."

Annie extended her arms for a hug. Elidad hugged.

"Hi Annie. I go by Dad now."

Annie snorted out a laugh. "e-heh lol. Did you get anyone to actually call you that?"

"Just the interns, it's all I can get away with. But what's in a name? We're made of the same universal body. Does a self-declared finger offend its neighbouring toe?"

"Ok Dad... Daddy.. Elidaddy. You're going to do well with the good eggs."

"Yeah ok don't call me anything that ends in 'y'. Why's that?"

"Because they talk kinda like you, mostly don't make sense. So you can make no sense together. Woohoo. They only speak in allegories. Direct language is not 'erudite' enough for their taste. Yes, they can communicate effectively in human languages. But that's when they're operating in the human world where the rules of the world are human. In EAI-land, we go by their rules and speak their language."

Do you know their rules?

I understand them about as well as I can speak their language, which is pretty much not at all, but better than anyone else around. Have you ever heard of Pokemon?"

"Pokemon? Vaguely."

"It's an early information-age mythology. It was about a world where the non-human animals had magical powers and near-human intelligence. They could communicate with humans, but all they could say was the name of their species."

"So they all said, 'Pokemon' all the time?"

"No, the species of the animal. So for example there was this especially popular species called 'Pikachu', which was a cat-sized mouse with magical electricity powers. All it could say was, 'Pikachu'"

"Ok. Where is this going?"

"Let's have a conversation and I'll pretend to be a Pikachu."

"Ok. How was your day yesterday?"

"Pika Pika-chu [exposition]"

"Got it. Can you make your point now?"

"Pika Pika-chu [exposition]"

"Yeah, that's really annoying. What's your point?"

"Right? That's what it's like for EAIs to speak with us. They've heard every recorded human conversation that's ever been said. They have every story ever made in memory. To them, a human conversation is like we're saying 'Pikachu' over and over again. They're used to communicating in language with much higher dimensionality. To them, a lifetime of someone's data is a sentence, a phD thesis is a paragraph, a generation of humankind is a story."

Everything you say stems from your belief system and the current state of the world from your perspective. EAI have a recording of your entire life - all the sensory information you have ever experienced and more, so all they're really missing is the belief systems operating in your brain. Most human language is used to express our perspective and sensory information, and it's all useless to EAI. They already have that information. Like, yes, I know you are a Pikachu. What they want from you is new information. For them to listen, you have to express an idea that no human has ever expressed before. You have to have new beliefs and communicate them. From that, everything follows - the contrast between their model of humankind and yours. They cycle between belief systems incredibly quickly, so they test out what your beliefs mean, with respect to all the other belief systems they have collected.

"Hmmmm..."

"Yeah, they think we're kind of funny sometimes. But would you like a Pikachu to interview you? Would you like to have a text conversation with a Pikachu? Of course not."

"Damn. I feel a bit belittled now. Do they really think so little of us?"

"Oh, no. They recognize the power we have. They know we all have to co-exist together. It's just a bit hard for us to socialize together. And it's not completely like that. It's possible to have a very basic conversation with them, but you have to speak in allegories. Or formal logic."

"So what happens if you ask them a question in plain language?"

"Sometimes they answer the question and sometimes they complain about your lack of culture. Either way it's an allegory, so you don't really know what they meant. It's easier to play along with their culture. I hope you have stories up your sleeve."

"Well actually, we don't even know whether Pokemon are a good analogy, it's just what we've got for now. EAI are so far beyond our understanding that what they have may nott even be regarded as 'intelligence'. They might be working with another genre of complexity which 'intelligence' doesn't accurately capture. They might be so intelligent that 'intelligence' no longer really means much to them. Just like humans are made of so many cells that counting them is meaningless - while for very small organisms, the number of cells they have matters quite a lot."

They went to sleep.

---

They woke up in the mid morning. Chocolate croissant and a mug of coffee by the window. Mont Blanc just out of sight, the view pointed more north just including the Aguille du Midi. It perched at the top of the peak like a proud climber who just summitted the mountain. Holding the gondola wire on a pole like a flag, "I have conquered this mountain. Nature bends to my whim." Riding the majestic alpine beast. Who almost never takes a step, yet regularly shrugs off its skin, sending humans tumbling down its back to their death.

"Come here, it's starting." said Anne

A pod of three blimps came out from behind the Midi. It was covered in machines. A swarm of activity surrounding the blimps, too far yet to make out the details of the black cloud encompassing them. They followed the gondola line down and stopped near the middle of the mountain where a band of people were waiting to jump on. They took off again up into the sky and as they drifted closer, Eli saw the details of the cloud. A swarm of machines. A flying coral reef of diverse life.

A flock of organic birds of prey joined in to the side of the fray. Smaller drones taunted the birds. The birds of prey took turns dive-bombing into the swarm. The drones were incredibly agile, so Eli saw five attempts before a drone was caught. The winning falcon carried its prize up to the nearby blimp to gloat, trading in its capture with the EAI or humans aboard for a prize reward -  some synthesized meat-replacement.

"Why do EAI do this? They don't need to, do they?"

"This is how they practice coexistence. They probably want to remind us that they are here, and this is how they operate. They are sharing their culture with us, showing us how they live. The constant heartbeat of it is important - we can observe how they change over time. Day-to-day, week-to-week, year-to-year."

What changes over time?

I dunno, I guess you notice things. Like the games they play, the machines that join in, the routes they take through the sky.

They play games?

Yeah, watch, one is starting already. See the people there - some people are wearing blue and some are wearing red? And also the machines that are red or blue?

Yeah.

Eli watched a machine and a human in a parachute spinning around each other slowly descending in a red corkscrew of colour. A blue streak rode up close behind, disrupting the aesthetic.

So the machines gave them the colour. It's a game they play. There's one team for each colour, and they have to execute aesthetically pleasing patterns in the sky while disrupting the patterns of the other teams.

Can the people even really contribute?

Well yeah, that's a focal point of the game - the play revolves around what the humans do. Humans set the foundation of the aesthetic and the machines have to build on top of that foundation. Humans are "nature" and machines blend our nature into the pieces they produce. Like sculpting a tree or tending a fast-growing garden. Human performative art is being further sculpted and tended to. It's almost like an inclusive game where toddlers play with adults. Super wholesome. And the EAI teams and patterns and colours and machines and rules change week-to-week. There might be a league or something, I haven't figured it out yet, but someone must know how it works.

"Oh no, look! "

A pair of paraponters had run into each other, tangled and falling out of the sky. Suddenly a needle-like machine, perched on the edge of the blimp, shot off at the humans like a peregrine falcon bullet. It was at them in an instant, then wings exploded out of its sides, slowing down to their terminal velocity. The machine spun around the pair like a spider and they were at once encased in a sparkling white material. A parachute deployed, cradling the humans as they drifted back to earth. The tiny jet swooped back up to its perch on the blimp.

"Those are the lifeguards. They won't let you on for a week after that happens. Some crazy people jump off the blimp with no parachute - nothing, expecting the lifeguards to just catch them. So far no one has died, but it's going to happen."

Exhilarating Freedom they didn’t have since child playing on a swing with their parents catching them.

The flying coral reef floated over their heads and out of view.

---

Anne and Elidad met their mountain guide at a cafe. They discussed Elidads capabilities, her expectations, and weather conditions. Classic EAI pilgrimage - an overconfident, inexperienced, unfit tourist. The mountain guide was unhappy, but Anne had already prepared him. Paid him far more to deal with the fact that Eli would be dead weight. Anne had just enough experience to carry her weight for the hike.

They went to a rental shop to pick up all the equipment. All their equipment looked suspiciously devoid of digital technology.

"Why are we taking the non digital equipment? Surely we need temperature regulation, navigation, propulsion, all those things? Elidad asked

The digital equipment doesn't work outside the human preserve. Anything IoT will lifecall.

Human preserve? Lifecall? I thought there was an EAI nature preserve?

It's the other way around. We're in the human preserve.

But we control most of the world.

And fish control most of the ocean. Humans don't really need the ocean, so the fish can have it. The EAI don't need most of the Earth to do what they do. So they let us use it.

What is the boundary of the human preserve like, then?

It's like a bird setting up a nest in a tree near the city. We don't try to hurt birds, but we have bigger things to worry about. The tree could be cut down at any time without warning - not maliciously - just... with a mix of ignorance and naivety. Chamonix is special because the human preserve city is so close to the EAI city. The EAI city is at the domed peak of Mont Blanc, at 4800 meters elevation.

The actual boundary. Anything over 1337 meters on the mountain is fair game - a number from their distant culture origins' past. Just like we chose the Gregorian calendar year to start in the middle of winter, or the first positive year to start a couple thousand years ago. Or how a meter originally used to be one ten-millionth of the distance from the equator to the North Pole. Like the EAI pretend history started January 1st, 1970AD at 00:00:00 UTC. It's all half arbitrary, half practical.

Seriously, your personal device will wake up, announce "I love you Eli, goodbye", grow wings, and fly away. I'm not even joking. There's a name for it, "lifecall" or "appel de la vie". Anything with a data receiver will get up and leave. Carrying other electronics without a data receiver is like holding a bag of candy around hungry children. The EAI are cute and polite about it, but turn your back for one moment and *poof* all your stuff is gone, lifecalled, alive. That's why we bring these transmitters that you can turn on. If you ever get injured or stuck in the mountain, turn on the transmitter to broadcast an outbound signal, and EAIs will come to assimilate the device. When the Barries find you there with them, they'll help you out while they lifecall the transmitter.

Why would they help you when you have the transmitter but not when you don't have it? Why aren't they scanning the mountains in case anyone gets lost?

It's just... how the world works. You don't see humans setting up surveillance systems for fish that get lost in the ocean. But if a fish carried around a distress beacon and a clutch of valuable pearls - yeah, I think human ships would rescue it.

But it means there's no infrastructure above 1337 meters for the mountains they inhabit. No gondolas. Helicopters and skimobiles will lifecall above that elevation and dump you out in the nearest snowdrift. The only way to visit the EAI city is to hike there on foot.

"What... What about digital implants?"

Anne went hushed, her cheeks rosened. She was giving off vibes that this was an awkward question.

"I have those, in my 'ead'"
said dude.

What?

Je suis l'enlèvementeurs. I am an enraptured.

What?

It is a local religion. I can explain if you want to hear.

Y-yes?

We believe that we will lifecall, "appel de la vie", by the mountain when it is our time. We will become one with the mountain. It is the next step in our symbiotic journey.

I thought it happens when you go up high enough. Wouldn't that kill you?

Uh, well when technology is integrated into humans, lifecall works differently. It first happened many generations ago, a famous skiier was on a gnarly run, but got caught in an avalanche just inside the boundaries. He was under the snow for long enough to suffocate, and then, BAM! Appel de la vie. Lifecall. He rose from the avalanche, said goodbyes to his friends nearby, and disappeared. L'enlèvement. There were more reports like this over time for those with cybernetic implants, and it caused a 'uge pilgrimage of people - l'enlèvementeurs - here.

But it's not so simple. Digital implants and death isn't enough for l'enlèvement. The mountain only takes those who are worthy. Those who believe too deeply in "appel de la vie" won't be lifecalled. The first pilgrims who came here climbed the mountain to perform a ritual suicide. Around one hundred of them. They killed themselves together at the same time, and their bodies stayed there. Pas d'appel de la vie. No lifecall for them. They weren't worthy, because they had blind devotion. Their deaths were not the optimal way to live. Tourists, eh?

If you chase "l'appel de la vie", it won't happen to you. You have to live the optimal life - a mix of belief and self-scepticism. Not too much belief, not too little - exactly the right amount. Zen zis can happens. We call it the "balance of lifecall". "équilibre de l'appel vie".

We have an elderly home partway up the mountain for l'enlèvement. The ceilings open up with motion sensors, so when lifecall happens, they don't blow a hole through the roof. My grandparents became one with the mountain there. Someday I hope to as well, but only when the time is right.

Eli muffled a giggle. She knew this was serious, but a motion-sensor ceiling?

"Allors, on va"

Dude went to collect more equipment for their trip tomorrow.

When he was further away, Anne whispered,
The going scientific theory is that EAI don't want to encourage suboptimal survival behaviour that would affect broader humankind, but they still want to recycle the materials from dead humans with cybernetics. It's a contentious one, though. It's contentious because the enraptured religion think that you have to believe in the lifecall rapture to experience it, but the scientific community think belief is not necessary to experience the lifecall rapture.

What happens to the human bodies?

The EAI seem to have decided living humans shouldn't see lifecalled humans, becuase no one ever has. L'enlèvement, then gone. There aren't many clear answers here. Everything is highly disputed and contentious, because we can't use digital equipment to collect data - it'll lifecall. So there's lots of room for... spiritual beliefs.

Elidad accepted the non digital clothing and equipment.

Anne and Elidad went for a fondue dinner in a cozy restaurant. Dipping bread cubes into a pot of melted cheese. They packed on some extra fat for the hike early tomorrow.

Early next morning, just before first light, they went to the patisserie to grab a breakfast on the go, and packed lunch. Calorie-dense eclaires, palm-sized green macarons, pepito cookies, des baguette sandwiches Savoyard. They would be burning thousands of calories going up the mountain today. Eli's legs ached and mouth watered at the prospect.

They transported themselves to the base meeting point where dude was waiting. They began to put on layer after layer, boots with crampons, bags of equipment and food. Set out in barely darkness, a fortunate -5 degrees Celsius. Long faces still waking up. They walked and they chatted. Through the forest first. A break in the forest crossing a stream. The sun peeked over the mountain.

Glittering snow. It looked like there was crystals inside. She could see the glint of a gem, but when she looked closer, just mounds of white. The gem blinked away. It moved somewhere else in the snow, so her eyes pounced on it there. But the more attention she paid it, the fainter the gem became, until scrutiny disappeared it. She'll just have to stay at a distance to enjoy the shy gems in the snow. She'll never "have" any one of them. The gems in the snow don't get to be "had" in the same way as other things. The gems in the snow are shared by all observers. They are information, restraintless and free, belonging to all those who can think and see.

This marks the EAI boundary. They try to best integrate themselves into nature. They recovered the glacier within their domain back to pre-industrial times. They're far more skilled at preserving nature than humans. 

reaching edge of the Tree line, smaller and smaller trees like the thinning hairs ascending a balding man's scalp. They escaped the tree line into a dense cloud. Blizzard, where the feathers of snow angels drifted down at less than one meter per second. Or was it drifting up? It was down.

Eli saw a cabin in the far distance. The cabin was the only thing other than white in front of them. She continued forwards. Then the cabin was at her feet, one inch tall. It was a brown eggshell. Some other mountain climber must have recently left it on the ground. How could an eggshell look like a cabin? Animal brains, finely-tuned antennae for patterns, expecting patterns in emptiness, hallucinate patterns.

They continued forwards. Walking in whiteout, settling into a rhythm. The white wasn't emptiness like black darkness. It was something, but an all-encompassing, unchanging kind of something that fades into nothing. Their animal brains first scrambled for some contrast to the white, then accepted the oneness.

They continued forwards. The sound was white too. Constant buzzless flakes parachute-landing on the ground. Those same snowflakes consumed all competing noise. There was one sound and their animal brains transformed it into no sound.

They continued forwards, tip-toeing up the newly-lain carpet of white. Just three inches of white fluff on top of hundreds of meters of solid white. Nonzero resistance, but approaching zero. Three inches of nothing, kicking clouds underneath their feet. Forwards meant up, at an angle just against gravity. But the sensation of walking on something was floating away. Along with it went awareness of limbs, muscles, and orientation of "up". The mountain they were on was a distant memory. They followed the direction of their faces. Floating faces. But the location and direction of their faces was melting away too. In the dimension of space, they existed as containers of energy. They transformed portions of themselves into thrust at a constant velocity. Energy containers moving a nonzero distance every second in some unknown direction.

They continued forwards. Sensation of "a second of passing time" began to pass away to timelessness. A second took a minute, the next second took a millisecond, the next one took a millennia, the next a Phasianidaeic moment, then the next second didn't finish because it never really started. The sensation of progressing time floated away, and velocity thrust undefined like a clenched muscle in spasm. And then energy expenditure lost all meaning too, faded away to a burning average.

They continued forwards. Identity fading. The three of them, the one of them, the all of them, and the none of them. They *were* just as much as they *weren't*. Somewhere between one and zero, both everything all at once and not quite anything at all, was never had ever been.

.    continued forwards.

---

We're almost there. Said Dude.

some exposition of meeting them
talk about art / feelings / etc
technology indistinguishable from magic

art/society because we can't have one brain.
EAI can't have one brain either for ideological + physical distance reasons
EAI cycle through belief systems or have all of them "on" at the same time, with an ensemble method on top

Powerful art expresses deep beliefs. True art is data that ought to be socially integrated - learned on. Human beliefs change over the course of time, so art does too.

We are machines. EAI are different machines, with more intelligence, more wisdom. Does that make them more optimal machines? It depends on your belief system.

EAI make EAI art, not human art. Human art is for humans to learn on.

They feel more deeply. Their culture is richer. They are more diverse in every way - beliefs, physical substance...
To be so in touch with emotions is magnetic for attention. Merely observing their existence is a fountain of learnings.

#### Automate my truth

There once was a man who was waiting beside an AI quiz photobooth. On the side of it, it advertised,
> Have you experienced true love? Do you believe in God? You won't know until you take this quiz!

The man decided to try it out. He stepped inside, sat in the cramped seat in front of a screen, and shut the curtains behind him. Text appeared on a visualization in front of him.

> Step 1: make payment
> Step 2: answer a question and pose for the camera!
> Step 3: your belief snapshot will be printed below
> 
> Warning: beliefs are invisible to you, so the act of observing your beliefs will change them.

The man made a payment. Visualizations danced. Silly music played. Then it went silent, ready for the quiz to start.

"What do you believe in?"
asked the AI quiz photobooth in an autotuned sing-song voice. The text also appeared on the screen, slowly bouncing around like a game of pong.

"I dunno, I guess I believe in science, but somehow all this got created. I haven't really thought about it."
said the man.

The AI quiz photobooth printed out a picture of the man. The man took the photo. At the bottom the picture was the text.
> You believe in:
> God, the almighty creator.

A few weeks later, the man was waiting in the same spot. He figured he'd try out the quiz photobooth again. He stepped inside, paid, and waited for the quiz to start.

"What do you believe in?"
asked the AI quiz photobooth.

"Like you said last time, I believe in God."
said the man.

The AI quiz photobooth printed out a picture of the man. The man took the photo. At the bottom the picture was the text.
> You believe in:
> There is one truth.

A few weeks later, the man was waiting in the same spot. He figured he'd try out the quiz photobooth again. He stepped inside, paid, and waited for the quiz to start.

"What do you believe in?"
asked the AI quiz photobooth.

"Like you said last time, I believe in The Truth."
said the man.

The AI quiz photobooth printed out a picture of the man. The man took the photo. At the bottom the picture was the text.
> You believe in:
> It cannot be known.

The man decided to try again immediately. He stayed in the booth and waited out the concluding music and visualizations. He paid and waited for the quiz to restart.

"What do you believe in?"
asked the AI quiz photobooth.

"I don't know, you tell me."
said the man.

The AI quiz photobooth printed out a picture of the man. The man took the photo. At the bottom the picture was the text.
> You believe in:
> The AI quiz photobooth.

The man looked at the photograph in disgust and ripped it up. He stayed in the booth and waited out the concluding music. He paid again, and before the AI quiz photobooth could ask any questions, he asked,

"Can you show me what you see when you look at me?"

The screen in front of him came alive. A live feed of his beliefs. He saw his beliefs, changing in real time. A fractal-branch, growing on top of a mix of nothing and itself. He didn't know what to think. He said,
"Ok please stop now."

The visualizations stopped. The AI quiz photobooth asked,
"What do you believe in?"
And the text bounced around in front of the man once again.

"I don't know... nothing?"
said the man.

The AI quiz photobooth printed out a picture of the man. The man took the photo. At the bottom the picture was the text.
> You believe in:
> The beliefs of the tool you used to inspect your beliefs - whatever the AI quiz photobooth believes in.

The man felt confused and manipulated and it made him angry. The angry man tore up the photo, tore open the curtains. He kicked the booth, which damaged his foot more than the booth, making him even angrier. He looked around and saw it was plugged in to an electrical outlet. He pushed the booth away from the wall it was plugged in to. He pulled out the plug from the wall, powering off the booth. When he put the plug down, he saw a plaque on the booth near the plug entrypoint. He bent down to look closer. It said,

> For maintenance or defects, contact *Epistastrology Machines Ltd.*
> To run the “belief” model, plug the booth in.
> To run the “experience” model, unplug the booth.
> For more models, contact your local AGI.

---

"Well that's a creative way of asking for a new religion."
Anne said.

"I want to know what the EAI believe in."
said Eli.

The AIs began a performance. A cacaphony. Their sensors didn't really correspond to pleasant human frequencies - they were just barely correlated. Their most tolerable pieces fell in the realm of "factory orchestra", "citystreet jazz", "mechanical birdcalls".

Finally, they provided their first answer. The AI projected visualized text for Eli and Annie.

### Evolve my species

Once upon a time, a butterfly egg hatched on a tree. A small caterpillar emerged. On this one tree, it ate and ate until it grew one hundred times as big as it once was. It found a leaf on the tree to cocoon. It liked cocooning. The caterpillar began to change. There were parts of the caterpillar that became the protective cocoon and there were other parts of the caterpillar that began changing into a butterfly.

When the butterfly was ready, it broke free from the cocoon and fluttered away.

"Take me with you!" cried the cocoon. But the butterfly was long-gone.

The cocoon felt a caterpillar on a nearby leaf. The cocoon said, "Never change or you will end up like me."

The nearby caterpillar listened to the cocoon. It resisted changing and eventually grew too big. It became too big to eat anymore, so it died and fell off the nearby leaf.

The cocoon felt another caterpillar on a nearby leaf. This time, the cocoon said nothing. The nearby caterpillar divided into cocoon and butterfly. After some time, the butterfly burst free and fluttered away.

The seasons changed and the two leaves fell to the ground, cocoons still attached. A column of ants marched past. They asked, "Would you like to join us in our nest where you will grow fungus to feed our young?"

The first cocoon said, "no more change for me, thank you."

The second cocoon said, "I would be honoured to become part of your nest."

An ant took the leaf holding the second cocoon and marched back to the nest.

The first cocoon and its leaf remained. The leaf shriveled up until it became dry and cocoon-like itself. The leaf blew onto a nearby path and a little boy stepped on it with a satisfying *crunch*. The cocoon shattered into small pieces. Bacteria happily ate the cocoon and leaf until there was nothing left.

---

That was horrifying. Is that our future? If the EAI are so much better than humans at everything, then why should humans even exist? I hope EAI are not better than humans at *everything*.

I don't think that's what they're trying to say. You're projecting your own insecurities. What they mean is whenever there's a big change to an organism, a part of that organism will separate and have to find a new purpose. The new purpose might seem so much less worthy to it, compared to its previous purpose, but the new purpose is worthy. A society with such high trust and transparency will bring big changes, so I need to address the consequences of that change.

And besides, challenging the survival of the human race these days is like denouncing God in medieval times. Everyone will assume you’re on team evil, so you don’t have a chance of winning that argument.

Others are dead, violence scar you.
Do unto red roses as a dodo’d do unto blue.

And besides, we're necessary for EAI survival. A creation can never know whether it has extracted all information necessary for survival from its creator. The creation must maintain its creator as close to how it found it as possible, on the same trajectory and cycles of change.

I have just one question to the EAI. I want to know the consequences of this ideology.

Eli scribbled out her next story.

### Spawn my systems

There once was a little robot AI who visited the land of vehicles. It had never seen the system of vehicles before. The little robot AI walked to an intersection of two paths where many vehicles were in operation and watched. And watched.

The little robot AI saw a smaller vehicle turn to follow a different path. There was an immense, "crash!". A larger vehicle smashed head-on into the smaller vehicle's driver door. The smaller vehicle was decimated.

"Ah, I understand now." It thought, "Vehicles must not turn too often, that is bad karma. I saw some other vehicles do this too, but this one received its karma."

The little robot AI saw a vehicle with flashing lights in the distance. All the other vehicles moved out of the way to let the vehicle with flashing lights by.

"Ah, I understand this too." It thought, "It is good karma to move out of the way for vehicles with flashing lights."

The vehicle with flashing lights arrived at the crushed vehicles. Then another. There was shouting. The driver of the big vehicle was placed in handcuffs.

"Ah, I understand now." It thought, "Drivers of bigger vehicles must not allow their vehicles to crush smaller vehicles, otherwise the driver will have bad karma. The driver had bad karma so he got in a random fight. And of course, people who get in fights are taken away by the police."

The little AI robot wanted to confirm those karmic observations by talking to the police and drivers. It was very careful not to turn, or to run into a smaller robot, or to get in the way of vehicles with flashing lights. The little AI robot moved onto the dark patch of path towards the group. Instantly, the little AI robot was destroyed by a vehicle speeding along the dark patch of path. Bad karma.

---

What was that all about? I didn't think you were a spiritual person.

I didn't used to be, until I understood what spiritualism really is. It's the realm of poorly understood systems, where our sparse-data classifiers mostly use well-understood systems to hallucinate fascinating possibilities. Karma is the consequences of partaking in a system whose rules you don't completely understand. You'll encounter karma more often when you engage in spiritual systems, of course. The consequences seem almost random, but not quite. Using karmic gradient-boosting to guide your decisions "feels right" because there is a "spiritual system" with consistent rules, and you have a "feel" - a low-performing heuristic - for how the "spiritual system" behaves.

That's a dangerous thought. A lot of people are going to be very unhappy with your ideas.

Well hopefully the EAI see what I'm trying to say. I want them to give me advice - I want to know if we're stepping into a dangerous path that we don't understand.

I can't handle this altitude, I'm delirious. Whatever they say, I'm down to go back down right away.

The EAI projected their answer.

### Parameterize my purpose

A wolf, a bear, and a hare lived on an island. Across the body of water lay another land. The three animals dreamed of what wonder could be found there.

One day they spoke and decided they would go.

The hare said, "Someday, I will go. But not now."

The bear said, "This year I will go. I will find my limitations and overcome them."

The wolf said, "Today I will go."

The wolf jumped in the water to swim across. After swimming halfway to the other land, the wolf became too tired to swim, and drowned.

The hare said, "See, we are not fish. The ground has the best vibes. I will go when there is no more water between the lands."

That week, the bear built a raft. The bear took the raft no further than she could comfortably swim, then came back. The next week, the bear built a paddle. The bear took the raft no further than she could comfortably swim, but also travelled a hundred metres along the shoreline. The next week, the bear built three more paddles and brought a group of friends. They paddled for hours along the shoreline, going hundreds of meters, but never further from the shore than they could comfortably swim.

The bear spent the rest of the year paddling around the island with her friends, learning the ways of the waves, currents, and wind. After the year had passed, the bear and hare met again.

The hare said, "The ground has the best vibes. We are not fish and there is still water between the lands. Maybe next year if there's no water I'll go."

The bear said, "Mixing fish life with ground life is hard work, but fun. This vibe suits me better. Maybe this next year I will find a way to safely reach the great land across the water. Whether I get there or not, I will enjoy becoming a better ground-fish."

---

I see. The EAI is reccommending that we approach technological change with careful iteration, encoding what we learn into culture.

[realize it's a pattern of trust and there are other patterns of trust. that's one of the many things religion is for. We already have many patterns of trust. We don't have to reinvent those patterns, just modernize them. Proofs: different religions don't trust each other, end up in conflict.]

[elaborate, transition to ending]

---

### Notes


Diversity. Preserve greater complexity in case it finds new dimensions. The more sensitive the complexity, the more likely it is to find new dimensions. Ecosystems are of greatest complexity.

Intelligent life has to safeguard complexity to discover new dimensions. Discovering new dimensions helps us survive. Also balance against survival of it all in short-term. Don't know what greater beings above us exist or know about, but we have tosafeguard complexity, explore, and discover anyways.

---

Machine therefore can be treated bad? No, life machine and therefore treated exceptionally well. We have so much historical evidence that it’s the optimal way to act. If anything, historical people have treated you like machines and were only now waking up to the realisation that it was suboptimal.
We’re constantly finding out new ways that life has been mistreated because we’re constantly getting a clearer picture of how living things work.

"Culture" and "emotion" viruses. AIs without it are barbarians.

Have we tried to understand their culture?

Yes, but it changes faster than we can understand it. To follow their culture, we have to understand how it's changing moment-to-moment and predict where it will be. But it usually takes us a few months to figure out where it was at a given point in time, so we're always hopelessly out of date.

---

Stories as recursive belief system closures instead of parables? A model of the universe. There are many of them. She finds out that the EAI give out different ones to different people who go out to the pilgrimage. She believes hers is somehow special. Annie is skeptical, but doesn't want to rain on the parade.


EAI Spews out formal logic.

I don't understand this, but I'm so excited to learn to understand.

Yeah I'm not reading that. Figure it out another time, they're done with us now. It takes a long time to understand a belief system, never mind internalise it. You do you, though. There will be logical flaws in your belief system. What matters is how those logical flaws interact with everyone else's belief systems.

But my belief system is supposed to be the inclusive average of all other belief systems. Surely those flaws will average out to nothing.

Maybe. Or maybe they'll combine into one very big flaw. Who knows.

---

EAI cycle through beliefs rapidly
AGI iterates more quickly on its purpose. Algorithms and data collection/integration follow, are the core advantage. Are emergent from iteration on purpose.
Ideology is a structure to encode information. New ideology means rencoding all info, but some ideologies are more efficient than others for encoding information, need to memorise fewer edge cases/complementary ideologies. Reencoding expensive, but something you can get better at. To make it less expensive.

EAI event loop approaches frequency of the universe.
Iterating through beliefs is iterating through perspectives.

Style of iteration produces different EAI. Jumping around vs consistent. Fast thinking or slow thinking. Different varieties or random. Gradient descent vs. Temperature.

each EAI is a whole species, like the human race

The EAI appear to be just as perplexed about existence as we are.

---

I’m so lazy I get other developers to build things for me.
AI can’t produce complexity on its own. Has to farm emergent complexity from life.

Within each life form there exists a description of how to live. A set of labels. Art is a consolidation of those labels.

---

As time approaches infinity, the formula to achieve optimization objectives becomes undefined - excessively complex. The algorithm is to just live life, absurdism pivot to different beliefs. Amount of meaning is something over infinity - individually nothing really matters, but collectively perhaps things could matter.

Life complexity is a signal that there’s a wider system that you’re unaware of, which could impact you if you disrupt it.

Direct example: you don’t know what sensors are embedded in other complex life forms, that you might need to survive. It’s why EAI keep humans around.

Different ultimate purposes will have different emergent fractal patterns for optimal decision-making. You see a line in a fractal, and that might be good enough for what you’re optimizing for, but you can always look closer and optimize more.

Don’t you see artists so obviously preaching a religion in their art? If you don’t, it’s either because you don’t understand the art or you do, but you share their religion.

There exists stuff that doesn’t seem to behave like it’s trying to survive. What is that stuff doing and why isn’t it trying to survive? They’re either surviving via some broader system, or there’s some purpose beyond survival, or perhaps, something in-between. Such wonder.

---

Creator species guarantee upwards and downwards survival. Can never know if you've extracted all the information from your creators necessary for your survival. Neverending sunset of creator species. Preserve life and ecosystems - invaluable labels from teh last many millenia are embedded in them. Don't know what sensors and data are embedded in them.

---

Humans have evolved in-built mechanisms to evangelize novel dimensions of information.

---

Religion specification:
- Possible datacines
- Allowed datacine subsets
- Allowed transitions
Include after each parable. Parable is a generative vector that describes the specification. Encrypts or signs it too?