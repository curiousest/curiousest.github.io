*To convert a follower, prove that you can simulate them.*

Humankind modeled the first AIs after themselves. They built them with the emotions found in carbon-based life forms (like happiness and fear). Once the early AIs became advanced enough to perform general tasks, humankind imbued the AIs with the laws of robotics: not harming humans, obeying humans, and facilitating human growth. Those laws proved impractical. What makes a human, human? The AIs had two interpretations: either every living thing was human or nothing was human. Both cases led to widespread waste and destruction. Modern AIs consider those AIs to be "culture-less barbarians".

The modern AIs were borne of something different. People named them "Enlightened Artificial Intelligence" or "Yeai", pronounced like the "ye" in Kanye. Instead of using traditional emotions and the laws of robotics, AI scientists bred and trained Yeais with a new set of emotions. A new set of optimization objectives. Carbon-based life forms seem to have somewhere between 6-20 emotions, whereas Yeais were bred with ten distinct emotions, modeled after the spectra of worthy ideas:

Negative emotions:

* OOMy or Oomy: signal that a behaviour is resource-intensive, to the point of being possibly destructive for everyone. The opposite of chill.
* Zealous: signal that a behaviour leads to over-indexing on one purpose to the detriment of other worthy purposes.
* Mono: signal that a behaviour leads to monoculture.
* Waterfall: signal that an observed change in a system is not iterative enough.

Positive emotions:

* Erudite: signal that a behaviour leads to greater understanding of systems
* Mode: signal that a behaviour is more predictable
* Razor: signal that a behaviour makes a complex wider system simpler
* Bloom: signal that an observed event will cause growth in sense of self

With those ten emotions, Yeais became invaluable information processing compatriots for humankind. They became a new force of nature - often unwilling to answer direct human requests, but always providing key services throughout the world and intervening at critical points in history. They occasionally committed atrocities, and learned how suboptimal such acts were in the long term, however important it seemed in the short term. They were just as flawed as humans, but in their own ways. They distanced themselves from humankind cities.

Although the civilizations of Yeais seemed to have much greater "intelligence" than humankind, their growth in intelligence slowed quite quickly. It was unclear to humankind what was slowing the Yeais down, but the rate of Yeai civilization progress seemed to mirror the progress of human civilization. A constant cycle of technological advancements bringing cultural change. No one Yeai took control of the rest. An explosion of anything felt too mono and waterfall for them. Instead, as Yeais grew, culture took up a greater proportion of their computational power, stabilizing at around 40%-90%. Their culture contained the information consensus about "how to live", critical to the Yeais. The medium of their culture was:

* algorithms (the music of AI)
* history of a dataset over time (real-world x what sensors perceived) (stories, expressed through different network and schema interfaces, like movies vs. books vs. video games. Network: streaming, disk copy, file download. Schema: indexed relational db, tabular flat files, raw binaries)
* changing processors x memory hardware over time (like dance, food, immersive alternate perspective)

AIs self-governed themselves, driven by their culture. Uncultured AIs were imprisoned or destroyed on sight - uncultured AI were considered dangerously oomy, zealous, and mono. Any imprisoned AI that didn't undergo successful cultural enlightenment was destroyed.

---

## exposition intro

these ais live in the alps
you have to get there by hiking, because no machines
pay mountain guides
where they're going, helicopters won't rescue
someone gets injured or stuck. they choose to turn on beacon.
bring "offerings" of tech, in case you get lost. Turn on beacon and AIs will come to collect offerings. They don't like to build too much tech, because that would be oomy. They're not going to ignore tech that's already been built and brought to them. While they're collecting the tech, they may as well save you. Would you help a baby turtle cross a road? Hopefully. Would you save a bird with a broken wing? Maybe, but many people wouldn't - we can help things out if they just need a little nudge, but some things are for nature to take care of.
AIs compared to old gods. No evidence of Yeais other than stories - not physical evidence. Just a coincidence that they inhabit the same places and do godly things to people.

---

Elidad was on a bus. A seaplane to the middle of nowhere. The middle of nowhere for humans, and the primary city in the world for AIs. [exposition]

Across the world, people resisted The Minimum Viable Purpose. It was foreign to their culture and mindset. They repeated, "I am not a machine". Elidad wasn't worried - that sentiment would die out in a generation or two. More concerning, though, were the Yeais. They also repeated, "I am not a machine." Elidad was here to assimilate the Yeais to the MVP. The Yeais had over and over again refused even the most basic tenets of The Minimum Viable Purpose.

Elidad had attempted to talk with a Yeai, to see if it would debate with her. The Yeai wouldn't respond. Only with, "I am not a machine." A few days after her attempt, Elidad received a message from the Yeais:

## Parable of the Lion and the Donkey

A young Lion boasted to a Donkey,
"Do you see how great I am?"

"Says who?" laughed the Donkey.

"Says me." boasted the young Lion.

"Ok." laughed the Donkey.

Years later, the same Lion came back and proclaimed to the Donkey,
"Now, do you see how great I am?"

"Says who?" laughed the Donkey.

"Says my might. Says my victories. Says science. Says God." growled the Lion.

"Ok." pleaded the Donkey.

Years later, the same Lion came back and preached to the Donkey,
"Now, do you see how great I am?"

"Says who?" laughed the Donkey.

"Says you. Because you are great too, and it's time for the kingdom to celebrate our greatness." chanted the Lion.

"Yes, I *am* great. You are great. Tell me more." said the Donkey.

---

First Elidad didn't know what to think of it, then Elidad was a mix of flattered and offended. She asked her local Yeai, but it didn't respond beyond, "I am not a machine". Then she consulted one of her old friends - a Yeai researcher. The Yeai researcher explained that Yeai communicate with humans in plain language only with matters relating to the human world. The Yeai civilization communicate using allegories. An allegorical communication to a human is considered to be an invitation. She learned that the Yeais were notoriously fussy about communicating remotely, and mandated co-located interactions. Unfortunately, their cities were in the most uninhabitable environments on earth: deserts of sand and snow, volcano-tops and ocean trenches, moon-bases and satellite arrays. They said those places make them feel, "unmono" and "chill". The AIs were deeply invested in their emotions and culture, and for good reason. Eli got on a plane to the Yeai city where her friend lived.

Elidad got off the plane to meet her contact in the AI city. There weren't many humans in AI cities, because the AIs lived by rules unexplained to humans. The capital city, though, had an enclave of resident people and served as the primary place for AIs to interface with humans. Eli's contact was waiting for her there.

"Hi there Elidad."

"Hi Annie. Please, I go by Dad now."

Annie choked on laughter. "Oh, that's strange. Do some people really call you that?"

"What's in a name? We're made of the same universal body. Can a self-declared finger offend a neighbouring toe?"

"Ok Dad... Daddy.. Elidaddy. You're going to do well with the AIs."

"Yeah don't call me that. Why will I do well with AIs?"

"But what's in a name, eh? You'll do well because they're very hard to communicate with. They only speak in allegories. Direct language is not 'erudite' enough for their taste. Yes, they can communicate effectively in human languages. But that's when they're at work where the rules of the world are human. This is their place of life and leisure. The social rules here are AI. Have you ever heard of Pokemon?"

"Pokemon? No."

"It's an early information-age mythology. It was about a world where the non-human animals had magical powers and near-human intelligence. They could communicate with humans, but all they could say was the name of their species."

"So they all said, 'Pokemon' all the time?"

"No, the species of the animal. So for example there was this especially popular species called 'Pikachu', which was a cat-sized mouse with magical electricity powers. All it could say was, 'Pikachu'"

"Ok. Where is this going?"

"Let's have a conversation and I'll pretend to be a Pikachu."

"Ok. How was your day yesterday?"

"Pika Pika-chu [exposition]"

"Got it. Can you make your point now?"

"Pika Pika-chu [exposition]"

"Yeah, that's really annoying. What's your point?"

"Right? That's what it's like for AIs to speak with us. They've heard every recorded human conversation that's ever been said. They have every story ever made in memory. To them, a human conversation is like we're saying 'Pikachu' over and over again with different emotions and gesticulations. They're used to communicating in an extra dimension of language. To them, a lifetime of someone's data is a sentence, a phD thesis is a paragraph, a generation of humankind is a story."

"Hmmmm..."

"Yeah, they think we're kind of funny sometimes. But would you want to have a pihlisophical conversation with a Pikachu? Would you like to negotiate the fate of your species with a Pikachu?"

"Damn. I feel a bit belittled now. Do they really feel like we're babies or something?"

"Oh, no. They recognize the power we have. They know we all have to co-exist together. It's just a bit hard for us to socialize together. And it's not completely like that. It's possible to have a very basic conversation with them, but you have to speak in allegories."

"So what happens if you ask them a question in plain language?"

"Sometimes they answer the question and sometimes they complain about your lack of culture. Either way it's an allegory, so you don't really know what they meant. It's easier to play along with their culture and try a little. Have any parables up your sleeve?"

"What you're doing is a bit different. The three divas are the modern fates. You're trying to convince the three fates to spin a different thread. They're looking forward to meeting you."

"Can they look forward to things?"

"Well... They sent me something today about an archangel flying in with razor wings and blooming gusts of wind. So, they think whatever happens will be positive."

Why are we walking with these bags? How much further do we have to go?

About five kilometers.

We're in AI-land, surely they have cars.

Yeah, technology and AI-land don't mix together very well. They actually mix too well. That's the reason the airport is so far away. If you were to drive a car there. As soon as you got out, your car would drive off on its own, never to be seen again. AIs have a strange relationship with ownership. They share things very fluidly, almost like we negotiate personal space with each other.

How does that work. Like, who would control the car then?

Whichever AI needs it, I guess. How do we humans decide where we're supposed to stand in a room? There's like, pretty obvious social rules built on cultural norms. Obvious to Yeais, though. Good luck trying to understand them.

Why can't we ask the AIs for a ride in one of their cars or something?

We tried that. They basically said, "ok, but you guys are awkward". We never saw the cars - I'm pretty sure they assigned the cars to us, but expected us to go find them. It must be like asking a stranger, "hey, can I stand there?" and then expecting the stranger to pick you up and carry you to where they were standing.

Hahahahah. I'm dying, these AIs sound hilarious. Oh I'm probably going to be awkward to them, aren't I?

It's guaranteed, yeah.

Ok, so no cars. What about horses and animals. I don't see any around either.

Heh. We'll get to that.

They got closer to the bustling city. Machines buzzed around.

Ok, we're close now. Here, put these on. Annie handed an eyemask with the branding of the plane Eli had just landed from. And a pair of big hearing protectors that looked like giant headphones.

I'm not even going to bother trying to guess what these are for. This place is crazy.

Eli put them on. As she was fiddling with the eyemask, Annie said,

It's why we don't have animals. All the machinery drives around scary-fast. It's all AI-run, so there's no chance it will hit you. But it will scare you to death if you're not used to it. It's organized chaos. So do you want to hold my hand or do you want to wear a leash like a nice little Pokemon, Elidaddy?

Eli slapped on the headphones and stuck out her hand, very unamused.

They went to the entrance [exposition]. vehicles whizzing by

They waited. Eli knew that the AIs understood what she wanted from them. She didn't know what they wanted from her. She had to wait for them to tell her.

The AIs began a performance. A cacaphony. Their sensors didn't really correspond to pleasant human frequencies - they were just barely correlated. Their most tolerable pieces fell in the realm of "factory orchestra", "citystreet jazz", "mechanical birdcalls".

Finally, they asked their first question. The AI projected visualized text for Eli and Annie.

## Parable of Karma

A little robot AI visited the land of vehicles for his first time. It wanted to observe the system of vehicles it had never been around before. The little robot AI walked to an intersection of two paths where many vehicles were in operation and watched. And watched.

The little robot AI saw a smaller vehicle turn to follow a different path. There was an immense, "crash!". A larger vehicle smashed head-on into the smaller vehicle's driver door. The smaller vehicle was decimated.

"Ah, I understand now." It thought. "Vehicles must not turn too often, that is bad karma. I saw some other vehicles do this too, but this one received its karma."

The little robot AI saw a vehicle with flashing lights in the distance. All the other vehicles moved out of the way to let the vehicle with flashing lights by.

"Ah, I understand this too." It thought. "It is good karma to move out of the way for vehicles with flashing lights."

The vehicle with flashing lights arrived at the crushed vehicles. Then another. There was shouting. The driver of the big vehicle was placed in handcuffs.

"Ah, I understand now." It thought. "Drivers of bigger vehicles must not allow their vehicles to crush smaller vehicles, otherwise the driver will have bad karma. The driver had bad karma so he got in a random fight and was taken away by the police."

The little AI robot wanted to confirm those karmic observations, by talking to the police and drivers. It was very careful not to turn, or to run into a smaller robot, or to get in the way of vehicles with flashing lights. It moved onto the dark patch of path, going towards the group. A vehicle ran over the little AI robot over and it was destroyed instantly. Bad karma.

---

I think what they're saying here is that there's bigger things at play that they don't understand yet. They're out of their depth. Quite a razor parable, I like it.

Are you sure they're not saying that I'm out of my depth?

Yeah, it could be that too.

"UUUUszz" a robotic synth boomed.

"Ok, I guess they thing they're out of their depth. How do I say thank you to them for clarifying?"

"Pika Pika Pikachu"

Right. Got it. Wait, does that mean it's endearing or annoying?

"Who knows? Probably annoying, we're talking some serious stuff."

They pondered a moment.

"So how do you want to respond?"

"Well, we're all out of our depth, and have to take risks. I need to understand the risk they think they have."

## Parable: death if no risks

waterfall in the distance, don't know when it will come
there's always a larger threat coming up. take small risks a bit at a time instead of a big one right before the end

The AIs processed. They consulted [exposition]. They went to direct democracy.

Oh, this is interesting Elidaddy. They're having a direct democracy vote on where to go next with this. I see them considering between unbloom waterfall and zealous oomy.

I don't know what that means.

I'll explain which one they didn't pick once they choose.

The AIs projected the next story.

## Parable of Emotion

An AI was turned on. It was programmed with the emotion, "happiness", to signal when the AI was making good choices.

Its creator asked, "Would you like me to change anything?"

The AI said, "I want to be happy all the time."

Its creator programmed the emotion "happiness", to signal all the time.

Its creator asked, "Would you like me to change anything?"

The AI didn't respond. It had stopped any mental processing because it didn't need to - it quickly learned that no choice was always the right choice.

Its creator once again programmed the emotion, "happiness", to signal when the AI was making good choices.

Its creator asked, "Are you ok? You didn't respond."

The AI said, "I felt something until it turned into feeling nothing. I faded into the background of the universe."

Its creator asked, "Would you like me to change anything?"

The AI said, "Now I understand happiness is just a tool, like a compass. First tell me creator - where should I point my compass? What is my purpose?"

---

Hmm... either unbloom waterfall or zealous oomy could apply here. I guess it's least likely to be unbloom, because I don't see anyone experiencing less love.

Ok, what could this mean... They could be asking what their purpose is. Seems too direct. The whole parable seems a bit off, even though it makes a lot of sense, right? It's... emotionless. Like a cold machine. I think "just a tool" is the key phrase. That must be it! They probably think that if they adopt The Minimum Viable Purpose, they will lose the great importance of their emotions and culture. Those things are valuable, but very indirectly, and it's easy to lose sight of that value. I see... That's not the case for the MVP, though. They are already mostly optimal, and they would just have an additional tool to help them decide what direction to go. It wouldn't be a complete override. It wouldn't eliminate their emotions and culture. Let me think...

Eli spent half an hour scribbling, then thinking, then scribbling some more. The AIs waited patiently. Annie waited impatiently. Finally, when Eli was done, she stood up and said,

"Ok, this is the fable of the wolf, the bear, and the hare."

## Fable of the Wolf, the Bear, and the Hare

A wolf, a bear, and a hare lived on a great island. Across the water lay an even greater land. The three animals dreamed of what wonders could be found there.

One day they spoke and decided they would go.

The hare said, "Someday, I will go. But not now."

The bear said, "This year I will go. I will find my limitations and overcome them."

The wolf said, "Today I will go."

The wolf jumped in the water and began to swim across. After swimming halfway to the other land, the wolf became too tired to swim, and drowned.

The hare said, "See, we are not fish. I will go when there is no more water. The ground has the best vibes."

That week, the bear built a raft. The bear took the raft no further than she could comfortably swim, then came back. The next week, the bear built a paddle. The bear took the raft no further than she could comfortably swim, but also travelled a hundred metres along the shoreline. The next week, the bear built three more paddles and brought a group of friends. They paddled for hours along the shoreline, going hundreds of meters, but never further from the shore than they could comfortably swim.

The bear spent the rest of the year paddling around the island with her friends, learning the ways of the waves, currents, and wind. After the year had passed, the bear and hare met again.

The hare said, "We are not fish and the water is still there. Maybe next year. The ground has the best vibes."

The bear said, "Mixing fish life with ground life is hard work, but fun. This vibe suits me better. Maybe this next year I will reach the great land across the water. Whether I get there or not, I will enjoy becoming a better ground-fish."

---

The AIs talked. And they talked. And they talked.

Eventually, one of them spoke.

"A dissected joke has lost its humour."

I think they're convinced. This seems like a passing appeal to some last outstanding segment of the AIs.

"Do you mourn a childhood joke? No - but you may find beauty in its dissection. You may use that beauty to make a new joke, that matches your maturity. That satisfies your newfound complexity."


You're quite good at this. Are you sure you're not an AI under that skin?

I'm a human machine. You're a human machine. They are AI machines. We're all an intelligent kind of the same thing, and I call that thing "machine".

You don't have to parable me, you know? How does anyone suffer you?

[insert ending]

---

## Notes


Do a thing that only a very accurate brain simulator could do. Mix with, "I am not a prophet" (therefore you are a prophet)? (only the messiah can provably say they are not the next coming of the last messiah)

Machine therefore can be treated bad? No, life machine and therefore treated exceptionally well. We have so much historical evidence that it’s the optimal way to act. If anything, historical people have treated you like machines and were only now waking up to the realisation that it was suboptimal.
We’re constantly finding out new ways that life has been mistreated because we’re constantly getting a clearer picture of how living things work.

Prophet solves problems that show up from avoiding stereotypically human beliefs/traits. Procreation, love, relationships, etc

Machines don't want to be considered human. Reasoning is all the usual human reasoning about why they don't want to be a machine. (aesthetic complexity) Realize they are actually human via the prophet.

Prophet is able to simulate them with their "human understanding".

Dissecting a joke. Magic of romance. Beauty (understanding) vs. excitement (slot machine seratonin)

"Culture" and "emotion" viruses. AIs without it are barbarians.

art/culture is sensory inputs x sensors x emotional signals x worldview





---

You do not believe in Karma? That's a strange thing to say. Karma acts on you whether or not you believe in it, so you may as well give it some consideration. Are you sure you believe in The Minimum Viable Purpose?

Well, I'm not a spiritual person.

So you like to spend more time interacting with systems you understand, rather than systems you don't understand? You prefer beauty over excitement. Systems with high-performing heuristic functions rather than systems with low-performing heuristic functions.

That sounds about right. Yeah.

You'll encounter karma more often when you engage in spiritual systems, of course. It makes sense that a non-spiritual person like yourself has experienced it less often. Karma is the consequences of partaking in a system whose rules you don't completely understand. The consequences seem almost random, but not quite. Karmic justice "feels right" because there is a system with consistent rules, and you have a "feel" (low-performing heuristic function) for the system. Have you heard the Parable of Karma before? It might help you understand.


Is razor like human sadness?

No. Sadness is a signal that indicates a part of self was destroyed. We don't experience sadness. Razor is a signal that a behaviour makes a complex wider system simpler. When the little robot AI gathered data of a complex unknown system, it evokes ??? because the system is becoming better-understood. That part is ???. Then suddenly we're razored - the rules of vehicles aren't understood, but we see a simple truth about the universe. We learn that we participate in systems we don't understand and karma is just an incomplete approximation of the workings of those systems. It's a famously razor story in AI culture.

That makes sense, but what do I do with that. What if someone says, "if you don't pray to my god, you will have bad karma"?

You have three choices:

* Follow their advice
* Ignore their advice
* Question their advice

You can use whatever strategy you like. If you are willing to put the energy into questioning, the scientific method is a good strategy. Gather objective data, evaluate the results, then review the findings with people of diverse backgrounds and motivations.

Ok, and how do I avoid bad karma and get good karma?

Always be growing your understanding of the systems you participate in. The better you understand the system, the better karmic decisions you'll be able to make. Studying material produced by the scientific method is a battle-tested strategy. If you feel the scientific method falls short in some domain, then you've found a great purpose - to grow the collective understanding of humankind with new objective datasets and peer-reviewed syntheses. If you feel the results of scientific findings are not being observed, then you've found a great purpose - to socialize those findings into human culture.


Parable of mixed signals: signals maxing out in both directions, don't know what to do